{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the list of sofwares in Data Mining Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import re \n",
    "import pandas as pd\n",
    "import json \n",
    "import csv \n",
    "from urllib.parse import urljoin\n",
    "import time\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>URL to Capterra Page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Spider Impact</td>\n",
       "      <td>data analysis software</td>\n",
       "      <td>Spider Strategies</td>\n",
       "      <td>www.capterra.com/p/113352/Scoreboard/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Zoho Analytics</td>\n",
       "      <td>data analysis software</td>\n",
       "      <td>Zoho</td>\n",
       "      <td>www.capterra.com/p/129749/Zoho-Analytics/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Cluvio</td>\n",
       "      <td>data analysis software</td>\n",
       "      <td>Cluvio</td>\n",
       "      <td>www.capterra.com/p/162332/Cluvio/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Minitab Statistical Software</td>\n",
       "      <td>data analysis software</td>\n",
       "      <td>Minitab</td>\n",
       "      <td>www.capterra.com/p/109731/Minitab-Statistical-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Hexowatch</td>\n",
       "      <td>data analysis software</td>\n",
       "      <td>Hexact</td>\n",
       "      <td>www.capterra.com/p/206900/Hexowatch/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                  Product Name                 Category  \\\n",
       "0           0                 Spider Impact  data analysis software    \n",
       "1           1                Zoho Analytics  data analysis software    \n",
       "2           2                        Cluvio  data analysis software    \n",
       "3           3  Minitab Statistical Software  data analysis software    \n",
       "4           4                     Hexowatch  data analysis software    \n",
       "\n",
       "         Company Name                               URL to Capterra Page  \n",
       "0   Spider Strategies              www.capterra.com/p/113352/Scoreboard/  \n",
       "1                Zoho          www.capterra.com/p/129749/Zoho-Analytics/  \n",
       "2              Cluvio                  www.capterra.com/p/162332/Cluvio/  \n",
       "3             Minitab  www.capterra.com/p/109731/Minitab-Statistical-...  \n",
       "4              Hexact               www.capterra.com/p/206900/Hexowatch/  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\Dabu bahya\\Downloads\\Desktop\\f\\product_list.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>URL to Capterra Page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>581</td>\n",
       "      <td>Batch Data Collector</td>\n",
       "      <td>data mining software</td>\n",
       "      <td>Batch Data Collector</td>\n",
       "      <td>www.capterra.com/p/209952/Batch-Data-Collector...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>582</td>\n",
       "      <td>SPSS</td>\n",
       "      <td>data mining software</td>\n",
       "      <td>IBM</td>\n",
       "      <td>www.capterra.com/p/13990/SPSS/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>583</td>\n",
       "      <td>Wolfram Mathematica</td>\n",
       "      <td>data mining software</td>\n",
       "      <td>Wolfram</td>\n",
       "      <td>www.capterra.com/p/171048/Wolfram-Mathematica/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>584</td>\n",
       "      <td>Octoparse</td>\n",
       "      <td>data mining software</td>\n",
       "      <td>Octopus Data</td>\n",
       "      <td>www.capterra.com/p/150508/Octoparse/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>585</td>\n",
       "      <td>Mozenda</td>\n",
       "      <td>data mining software</td>\n",
       "      <td>Mozenda</td>\n",
       "      <td>www.capterra.com/p/102193/Mozenda/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>586</td>\n",
       "      <td>RapidMiner</td>\n",
       "      <td>data mining software</td>\n",
       "      <td>RapidMiner</td>\n",
       "      <td>www.capterra.com/p/148220/RapidMiner/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>587</td>\n",
       "      <td>SAS Enterprise Miner</td>\n",
       "      <td>data mining software</td>\n",
       "      <td>SAS Institute</td>\n",
       "      <td>www.capterra.com/p/157071/SAS-Enterprise-Miner/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>588</td>\n",
       "      <td>Orange</td>\n",
       "      <td>data mining software</td>\n",
       "      <td>University of Ljubljana</td>\n",
       "      <td>www.capterra.com/p/164505/Orange/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>589</td>\n",
       "      <td>Neural Designer</td>\n",
       "      <td>data mining software</td>\n",
       "      <td>Artelnics</td>\n",
       "      <td>www.capterra.com/p/156274/Neural-Designer/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>590</td>\n",
       "      <td>Apteco FastStats</td>\n",
       "      <td>data mining software</td>\n",
       "      <td>Apteco</td>\n",
       "      <td>www.capterra.com/p/101009/FastStats/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>591</td>\n",
       "      <td>uCrawler</td>\n",
       "      <td>data mining software</td>\n",
       "      <td>uCrawler</td>\n",
       "      <td>www.capterra.com/p/186866/uCrawler/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>592</td>\n",
       "      <td>Oracle Data Mining</td>\n",
       "      <td>data mining software</td>\n",
       "      <td>Oracle</td>\n",
       "      <td>www.capterra.com/p/169949/Oracle-Data-Mining/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>593</td>\n",
       "      <td>AlertMiner</td>\n",
       "      <td>data mining software</td>\n",
       "      <td>AutoAlert</td>\n",
       "      <td>www.capterra.com/p/197068/AlertMiner/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>594</td>\n",
       "      <td>limestats</td>\n",
       "      <td>data mining software</td>\n",
       "      <td>limestats</td>\n",
       "      <td>www.capterra.com/p/178789/limestats/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>595</td>\n",
       "      <td>Pitchly</td>\n",
       "      <td>data mining software</td>\n",
       "      <td>Pitchly</td>\n",
       "      <td>www.capterra.com/p/151099/Pitchly/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>596</td>\n",
       "      <td>PolyAnalyst</td>\n",
       "      <td>data mining software</td>\n",
       "      <td>Megaputer Intelligence</td>\n",
       "      <td>www.capterra.com/p/125821/PolyAnalyst/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>597</td>\n",
       "      <td>Coheris Analytics SPAD</td>\n",
       "      <td>data mining software</td>\n",
       "      <td>Coheris</td>\n",
       "      <td>www.capterra.com/p/171508/Coheris-Analytics-SPAD/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>598</td>\n",
       "      <td>Data.Mining.Fox</td>\n",
       "      <td>data mining software</td>\n",
       "      <td>Easy.Data.Mining</td>\n",
       "      <td>www.capterra.com/p/171506/Data-Mining-Fox/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>599</td>\n",
       "      <td>eccenca Corporate Memory</td>\n",
       "      <td>data mining software</td>\n",
       "      <td>eccenca</td>\n",
       "      <td>www.capterra.com/p/190219/eccenca-Corporate-Me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>600</td>\n",
       "      <td>EntelliFusion</td>\n",
       "      <td>data mining software</td>\n",
       "      <td>Teksouth</td>\n",
       "      <td>www.capterra.com/p/207622/EntelliFusion/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>601</td>\n",
       "      <td>ExportData</td>\n",
       "      <td>data mining software</td>\n",
       "      <td>ZIKU TECH</td>\n",
       "      <td>www.capterra.com/p/189877/ExportData/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>602</td>\n",
       "      <td>FS.net</td>\n",
       "      <td>data mining software</td>\n",
       "      <td>Symbrium</td>\n",
       "      <td>www.capterra.com/p/183884/FS-net/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>603</td>\n",
       "      <td>Keel</td>\n",
       "      <td>data mining software</td>\n",
       "      <td>Keel</td>\n",
       "      <td>www.capterra.com/p/171507/Keel/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>604</td>\n",
       "      <td>Ketrium</td>\n",
       "      <td>data mining software</td>\n",
       "      <td>Ketrium</td>\n",
       "      <td>www.capterra.com/p/187439/Ketrium/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>605</td>\n",
       "      <td>Optymyze</td>\n",
       "      <td>data mining software</td>\n",
       "      <td>Optymyze</td>\n",
       "      <td>www.capterra.com/p/137148/Optymyze/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>606</td>\n",
       "      <td>Piperr</td>\n",
       "      <td>data mining software</td>\n",
       "      <td>Saturam</td>\n",
       "      <td>www.capterra.com/p/183888/Piperr/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>607</td>\n",
       "      <td>PoolParty</td>\n",
       "      <td>data mining software</td>\n",
       "      <td>Semantic Web Company</td>\n",
       "      <td>www.capterra.com/p/171504/PoolParty/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>608</td>\n",
       "      <td>Repustate</td>\n",
       "      <td>data mining software</td>\n",
       "      <td>Repustate</td>\n",
       "      <td>www.capterra.com/p/201539/Repustate/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>609</td>\n",
       "      <td>Salford Predictive Modeler</td>\n",
       "      <td>data mining software</td>\n",
       "      <td>Salford Systems</td>\n",
       "      <td>www.capterra.com/p/169966/SPM-8-2/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>610</td>\n",
       "      <td>Seeq</td>\n",
       "      <td>data mining software</td>\n",
       "      <td>Seeq Corporation</td>\n",
       "      <td>www.capterra.com/p/171687/Seeq/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>611</td>\n",
       "      <td>Semantria</td>\n",
       "      <td>data mining software</td>\n",
       "      <td>Lexalytics</td>\n",
       "      <td>www.capterra.com/p/151930/Semantria/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>612</td>\n",
       "      <td>SyncSpider</td>\n",
       "      <td>data mining software</td>\n",
       "      <td>SyncSpider</td>\n",
       "      <td>www.capterra.com/p/211760/SyncSpider/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>613</td>\n",
       "      <td>Text Analytics Platform</td>\n",
       "      <td>data mining software</td>\n",
       "      <td>SetuServ</td>\n",
       "      <td>www.capterra.com/p/211552/Text-Analytics-Platf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>614</td>\n",
       "      <td>XLMiner</td>\n",
       "      <td>data mining software</td>\n",
       "      <td>Frontline Systems</td>\n",
       "      <td>www.capterra.com/p/151767/XLMiner/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                Product Name               Category  \\\n",
       "581         581        Batch Data Collector  data mining software    \n",
       "582         582                        SPSS  data mining software    \n",
       "583         583         Wolfram Mathematica  data mining software    \n",
       "584         584                   Octoparse  data mining software    \n",
       "585         585                     Mozenda  data mining software    \n",
       "586         586                  RapidMiner  data mining software    \n",
       "587         587        SAS Enterprise Miner  data mining software    \n",
       "588         588                      Orange  data mining software    \n",
       "589         589             Neural Designer  data mining software    \n",
       "590         590            Apteco FastStats  data mining software    \n",
       "591         591                    uCrawler  data mining software    \n",
       "592         592          Oracle Data Mining  data mining software    \n",
       "593         593                  AlertMiner  data mining software    \n",
       "594         594                   limestats  data mining software    \n",
       "595         595                     Pitchly  data mining software    \n",
       "596         596                 PolyAnalyst  data mining software    \n",
       "597         597      Coheris Analytics SPAD  data mining software    \n",
       "598         598             Data.Mining.Fox  data mining software    \n",
       "599         599    eccenca Corporate Memory  data mining software    \n",
       "600         600               EntelliFusion  data mining software    \n",
       "601         601                  ExportData  data mining software    \n",
       "602         602                      FS.net  data mining software    \n",
       "603         603                        Keel  data mining software    \n",
       "604         604                     Ketrium  data mining software    \n",
       "605         605                    Optymyze  data mining software    \n",
       "606         606                      Piperr  data mining software    \n",
       "607         607                   PoolParty  data mining software    \n",
       "608         608                   Repustate  data mining software    \n",
       "609         609  Salford Predictive Modeler  data mining software    \n",
       "610         610                        Seeq  data mining software    \n",
       "611         611                   Semantria  data mining software    \n",
       "612         612                  SyncSpider  data mining software    \n",
       "613         613     Text Analytics Platform  data mining software    \n",
       "614         614                     XLMiner  data mining software    \n",
       "\n",
       "                 Company Name  \\\n",
       "581      Batch Data Collector   \n",
       "582                       IBM   \n",
       "583                   Wolfram   \n",
       "584              Octopus Data   \n",
       "585                   Mozenda   \n",
       "586                RapidMiner   \n",
       "587             SAS Institute   \n",
       "588   University of Ljubljana   \n",
       "589                 Artelnics   \n",
       "590                    Apteco   \n",
       "591                  uCrawler   \n",
       "592                    Oracle   \n",
       "593                 AutoAlert   \n",
       "594                 limestats   \n",
       "595                   Pitchly   \n",
       "596    Megaputer Intelligence   \n",
       "597                   Coheris   \n",
       "598          Easy.Data.Mining   \n",
       "599                   eccenca   \n",
       "600                  Teksouth   \n",
       "601                 ZIKU TECH   \n",
       "602                  Symbrium   \n",
       "603                      Keel   \n",
       "604                   Ketrium   \n",
       "605                  Optymyze   \n",
       "606                   Saturam   \n",
       "607      Semantic Web Company   \n",
       "608                 Repustate   \n",
       "609           Salford Systems   \n",
       "610          Seeq Corporation   \n",
       "611                Lexalytics   \n",
       "612                SyncSpider   \n",
       "613                  SetuServ   \n",
       "614         Frontline Systems   \n",
       "\n",
       "                                  URL to Capterra Page  \n",
       "581  www.capterra.com/p/209952/Batch-Data-Collector...  \n",
       "582                     www.capterra.com/p/13990/SPSS/  \n",
       "583     www.capterra.com/p/171048/Wolfram-Mathematica/  \n",
       "584               www.capterra.com/p/150508/Octoparse/  \n",
       "585                 www.capterra.com/p/102193/Mozenda/  \n",
       "586              www.capterra.com/p/148220/RapidMiner/  \n",
       "587    www.capterra.com/p/157071/SAS-Enterprise-Miner/  \n",
       "588                  www.capterra.com/p/164505/Orange/  \n",
       "589         www.capterra.com/p/156274/Neural-Designer/  \n",
       "590               www.capterra.com/p/101009/FastStats/  \n",
       "591                www.capterra.com/p/186866/uCrawler/  \n",
       "592      www.capterra.com/p/169949/Oracle-Data-Mining/  \n",
       "593              www.capterra.com/p/197068/AlertMiner/  \n",
       "594               www.capterra.com/p/178789/limestats/  \n",
       "595                 www.capterra.com/p/151099/Pitchly/  \n",
       "596             www.capterra.com/p/125821/PolyAnalyst/  \n",
       "597  www.capterra.com/p/171508/Coheris-Analytics-SPAD/  \n",
       "598         www.capterra.com/p/171506/Data-Mining-Fox/  \n",
       "599  www.capterra.com/p/190219/eccenca-Corporate-Me...  \n",
       "600           www.capterra.com/p/207622/EntelliFusion/  \n",
       "601              www.capterra.com/p/189877/ExportData/  \n",
       "602                  www.capterra.com/p/183884/FS-net/  \n",
       "603                    www.capterra.com/p/171507/Keel/  \n",
       "604                 www.capterra.com/p/187439/Ketrium/  \n",
       "605                www.capterra.com/p/137148/Optymyze/  \n",
       "606                  www.capterra.com/p/183888/Piperr/  \n",
       "607               www.capterra.com/p/171504/PoolParty/  \n",
       "608               www.capterra.com/p/201539/Repustate/  \n",
       "609                 www.capterra.com/p/169966/SPM-8-2/  \n",
       "610                    www.capterra.com/p/171687/Seeq/  \n",
       "611               www.capterra.com/p/151930/Semantria/  \n",
       "612              www.capterra.com/p/211760/SyncSpider/  \n",
       "613  www.capterra.com/p/211552/Text-Analytics-Platf...  \n",
       "614                 www.capterra.com/p/151767/XLMiner/  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = df.query('`Category`.str.startswith(\"data mining\")')\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('data_mining.jsonl', 'w') as fp:\n",
    "    for i in range(len(new_df)):\n",
    "        url =  \"https://\" + new_df.iloc[i]['URL to Capterra Page']\n",
    "        if re.match(r\"#reviews\", url):\n",
    "            url = re.sub(r\"#reviews\",'', url)\n",
    "        else:\n",
    "            pass\n",
    "        driver = webdriver.Chrome(r'D:\\Downloads\\Desktop\\chromedriver')  \n",
    "        driver.get(url)\n",
    "\n",
    "        soup = BeautifulSoup(driver.page_source,\"html.parser\" )\n",
    "        soup_obj = soup.find('div',{'class':'ProductSummary__SummaryPanel-mcm4i7-6 hCwGXf'})\n",
    "\n",
    "        product = soup_obj.contents[0]\n",
    "        product_info = product.select('div > div')[0].get_text(strip=True) #this is info about the product \n",
    "\n",
    "        #for featured in \n",
    "        x = soup_obj.contents[1].h2.get_text()\n",
    "\n",
    "        if re.match(r\"Featured In\", x):\n",
    "\n",
    "            c = soup_obj.contents[2]\n",
    "            y = c.h2.get_text(strip=True)\n",
    "            if re.match(r\"Best For\",y):\n",
    "                d = c.select('div > em')[0].get_text(strip=True)\n",
    "                var = 3\n",
    "\n",
    "            else:\n",
    "                d = \"Not Available\"\n",
    "                var = 2\n",
    "\n",
    "\n",
    "            try :\n",
    "                e = soup_obj.contents[var]\n",
    "                f = e.select('div > p')[0].get_text(strip=True)  # company name\n",
    "            except:\n",
    "                f = \"Not Available\"\n",
    "\n",
    "            try :\n",
    "                g = soup_obj.contents[var]\n",
    "                h = g.select('div > p')[1].get_text(strip=True)  # product website\n",
    "            except:\n",
    "                h = \"Not Available\"  \n",
    "\n",
    "\n",
    "            i = soup_obj.contents[var]\n",
    "            j = i.select('div > p')[2].get_text(strip=True)  # founding year\n",
    "            if not j:\n",
    "                j = \"Not Available\"\n",
    "            else:\n",
    "                pass  \n",
    "\n",
    "            k = soup_obj.contents[var]\n",
    "            l = k.select('div > p')[3].get_text(strip=True)  # founding place\n",
    "            if not l:\n",
    "                l = \"Not Available\"\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        else:\n",
    "            c = soup_obj.contents[1]\n",
    "            y = c.h2.get_text(strip=True)\n",
    "            if re.match(r\"Best For\",y):\n",
    "                d = c.select('div > em')[0].get_text(strip=True)\n",
    "                var = 2\n",
    "\n",
    "            else:\n",
    "                d = \"Not Available\"\n",
    "                var = 1\n",
    "\n",
    "\n",
    "            try :\n",
    "                e = soup_obj.contents[var]\n",
    "                f = e.select('div > p')[0].get_text(strip=True)\n",
    "            except:\n",
    "                f = \"Not Available\"\n",
    "\n",
    "            try :\n",
    "                g = soup_obj.contents[var]\n",
    "                h = g.select('div > p')[1].get_text(strip=True)\n",
    "            except:\n",
    "                h = \"Not Available\"\n",
    "\n",
    "            i = soup_obj.contents[var]\n",
    "            j = i.select('div > p')[2].get_text(strip=True)\n",
    "            if not j:\n",
    "                j = \"Not Available\"\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "            k = soup_obj.contents[var]\n",
    "            l = k.select('div > p')[3].get_text(strip=True)\n",
    "            if not l:\n",
    "                l = \"Not Available\"\n",
    "            else:\n",
    "                pass\n",
    "        info = {'About Product': product_info,'Best For':d,'Company Name': f,'Product Website': h, 'Founding Year': j,'Founding Place': l }\n",
    "\n",
    "\n",
    "        new_soup = soup.find('div',{'class':'SpecTable__Root-sc-1jq5uy4-0 jZHgUG'})\n",
    "        len_of_new_soup = len(new_soup.contents)\n",
    "        # the listed price of the product, if given.\n",
    "        try:\n",
    "            price_heading = new_soup.contents[0].h3.get_text()\n",
    "            price = new_soup.contents[0].a.get_text()\n",
    "            listed_price = {price_heading:price}\n",
    "        except:\n",
    "            price_heading = new_soup.contents[0].h3.get_text()\n",
    "            price = \"Not Available\"\n",
    "            listed_price = {price_heading:price}\n",
    "        # for available features in Deployment, Training,& Support\n",
    "        ndic ={}\n",
    "        for i in range(1,len_of_new_soup):\n",
    "            s_obj = new_soup.contents[i]\n",
    "            heading = s_obj.h3.get_text()\n",
    "            new_obj = s_obj.contents[1]\n",
    "            nl = []\n",
    "            for i in range(len(new_obj)):\n",
    "                an_obj = new_obj.contents[i]\n",
    "                x = an_obj.select('div > div')[0]['class']\n",
    "                y= x[1]\n",
    "                if y == 'bqMKDC':\n",
    "                    q = an_obj.select('div > div')[1].get_text(strip=True)\n",
    "                    nl.append(q)\n",
    "\n",
    "            ndic[heading] =nl\n",
    "\n",
    "\n",
    "\n",
    "        another_soup_obj = soup.find('div',{'class':'Accordion__Root-sc-1jo79it-0 jGWhUg'})\n",
    "        # clicking all the buttons \n",
    "        for i in range(1,len(another_soup_obj.contents)):\n",
    "            h4 = another_soup_obj.contents[i].h4.get_text()\n",
    "            cb = \"//button[normalize-space()=\" + f'\"{h4}\"' + \"]\"\n",
    "            element = driver.find_element_by_xpath(cb)\n",
    "            driver.execute_script(\"arguments[0].click();\", element)\n",
    "\n",
    "        # extracting the corresponding features\n",
    "        nd = {}\n",
    "        for i in range(len(another_soup_obj)):\n",
    "            field_heading = another_soup_obj.contents[i].h4.get_text()\n",
    "            n_o_j = another_soup_obj.contents[i]\n",
    "            xyz = n_o_j.find_all('div',{'class':'FeatureList__FeatureCell-sc-1kxeq27-1 ifqTCQ'})\n",
    "            nl = []\n",
    "            for i in xyz:\n",
    "                zas = i.select('div > div')[1]['class']\n",
    "                sac = zas[1]\n",
    "                if sac == 'bqMKDC':\n",
    "                    q = i.select('div > div')[2].get_text(strip=True)\n",
    "                    nl.append(q)\n",
    "            nd[field_heading] = nl\n",
    "\n",
    "\n",
    "\n",
    "        newurl = urljoin(url,'reviews')\n",
    "        another_driver = webdriver.Chrome(r'D:\\Downloads\\Desktop\\chromedriver')\n",
    "        another_driver.get(newurl)\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                new_element = another_driver.find_element_by_xpath('//button[normalize-space()=\"Show more reviews\"]')\n",
    "                another_driver.execute_script(\"arguments[0].click();\", new_element)\n",
    "            except:\n",
    "                break\n",
    "\n",
    "        review_soup = BeautifulSoup(another_driver.page_source,\"html.parser\" )\n",
    "\n",
    "        ls = ['Overall','Ease of Use','Customer Service']\n",
    "        ratings = soup.find_all('div',{'class':'StarRating__Rating-sc-9jwzgg-1 cAGyvf'})\n",
    "        la = []\n",
    "        for x,y in zip(ls,ratings):\n",
    "            la.append({x:y.get_text(strip=True)})\n",
    "\n",
    "\n",
    "        try:\n",
    "            start = review_soup.find('div',{'class':'gtm-review-section'})\n",
    "            perm_list\n",
    "\n",
    "            for i in range(len(start.contents)):\n",
    "                empty_list = []\n",
    "            #reviewer info\n",
    "                qw = start.contents[i]\n",
    "                personal_info = qw.find('div',{'class':'ReviewerAvatarSection__ReviewerInfo-sc-1a80501-1 cSadMy'})\n",
    "                name = personal_info.contents[0].get_text(strip=True)\n",
    "                other_info = personal_info.contents[1]\n",
    "                designation = other_info.select('div > div')[0].get_text(strip=True)\n",
    "                working_domain = other_info.select('div > div')[1].get_text(strip=True) \n",
    "                usage = other_info.select('div > div')[2].get_text(strip=True)\n",
    "                reviewer_info = {name:[designation,working_domain,usage]}\n",
    "                empty_list.append(reviewer_info)\n",
    "\n",
    "            #reviewer ratings    \n",
    "                li = ['Overall','Ease of Use','Customer Service', 'Features', ' Value for Money','Likelihood to Recommend']\n",
    "                ra = qw.find_all('div',{'class':'StarRating__Rating-sc-9jwzgg-1 kCLiav'})\n",
    "                reviewer_ratings = []\n",
    "                for x,y in zip(li,ra):\n",
    "                    reviewer_ratings.append({x:y.get_text(strip=True)})\n",
    "                empty_list.append(reviewer_ratings)\n",
    "\n",
    "            #date    \n",
    "                date = qw.find('div',{'class':'ReviewSource__Root-lnjke6-0 iBAGLQ'}).contents[2].get_text(strip=True)\n",
    "                empty_list.append(date)\n",
    "\n",
    "            #review\n",
    "\n",
    "                review = qw.find('div',{'class':'ReviewCard__RightFlexItem-sc-18j15p9-3 cOmWnW ReviewCard__FlexItem-sc-18j15p9-2 bTVfYT'})\n",
    "                review_heading = review.contents[0].h3.get_text(strip=True)\n",
    "                overall = review.contents[0].find_all('div',{'class':'ReviewSection__Root-sc-189472c-0 icjcMH'})\n",
    "                review_text ={}\n",
    "                review_text['review heading'] = review_heading\n",
    "                for i in overall :\n",
    "                    text = i.get_text(strip=True)\n",
    "                    manip = text.split(':')\n",
    "                    header = manip[0]\n",
    "                    review_content = manip[1]\n",
    "                    review_text[header] = review_content\n",
    "\n",
    "\n",
    "                empty_list.append(review_text)\n",
    "                perm_list.append(empty_list)\n",
    "\n",
    "            p_name = new_df.iloc[i]['Product Name']\n",
    "            p_category = new_df.iloc[i]['Category']\n",
    "            new_dic = {'Product Name': p_name,'Category': p_category, 'Product Info': info , 'Price': listed_price, 'Overall Features': ndic ,'Category Features': nd ,'Overall Ratings': la, 'Review': perm_list}\n",
    "\n",
    "            writer = jsonlines.Writer(fp)\n",
    "            writer.write(new_dic)\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "        another_driver.close()   \n",
    "        driver.close()\n",
    "        time.sleep(10)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.000143682000271\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "pass\n",
    "pass\n",
    "time.sleep(10)\n",
    "end = timer()\n",
    "time_taken = (end - start) \n",
    "print(time_taken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dic = {'Product Name': \"p_name\",'Category': \"p_category\", 'Product Info': \"info\" , 'Price': \"listed_price\", 'Overall Features': \"\" ,'Category Features': {} ,'Overall Ratings': \"la\", 'Review': \"perm_list\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(11):\n",
    "with open('data_mining.jsonl', 'w') as fp:\n",
    "    for i in range(11):\n",
    " #       json.dump(new_dic, fp)\n",
    "#        fp.write('\\n')\n",
    "        writer = jsonlines.Writer(fp)\n",
    "        writer.write(new_dic)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Product Info</th>\n",
       "      <th>Price</th>\n",
       "      <th>Overall Features</th>\n",
       "      <th>Category Features</th>\n",
       "      <th>Overall Ratings</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p_name</td>\n",
       "      <td>p_category</td>\n",
       "      <td>info</td>\n",
       "      <td>listed_price</td>\n",
       "      <td></td>\n",
       "      <td>{}</td>\n",
       "      <td>la</td>\n",
       "      <td>perm_list</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p_name</td>\n",
       "      <td>p_category</td>\n",
       "      <td>info</td>\n",
       "      <td>listed_price</td>\n",
       "      <td></td>\n",
       "      <td>{}</td>\n",
       "      <td>la</td>\n",
       "      <td>perm_list</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p_name</td>\n",
       "      <td>p_category</td>\n",
       "      <td>info</td>\n",
       "      <td>listed_price</td>\n",
       "      <td></td>\n",
       "      <td>{}</td>\n",
       "      <td>la</td>\n",
       "      <td>perm_list</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p_name</td>\n",
       "      <td>p_category</td>\n",
       "      <td>info</td>\n",
       "      <td>listed_price</td>\n",
       "      <td></td>\n",
       "      <td>{}</td>\n",
       "      <td>la</td>\n",
       "      <td>perm_list</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p_name</td>\n",
       "      <td>p_category</td>\n",
       "      <td>info</td>\n",
       "      <td>listed_price</td>\n",
       "      <td></td>\n",
       "      <td>{}</td>\n",
       "      <td>la</td>\n",
       "      <td>perm_list</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>p_name</td>\n",
       "      <td>p_category</td>\n",
       "      <td>info</td>\n",
       "      <td>listed_price</td>\n",
       "      <td></td>\n",
       "      <td>{}</td>\n",
       "      <td>la</td>\n",
       "      <td>perm_list</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>p_name</td>\n",
       "      <td>p_category</td>\n",
       "      <td>info</td>\n",
       "      <td>listed_price</td>\n",
       "      <td></td>\n",
       "      <td>{}</td>\n",
       "      <td>la</td>\n",
       "      <td>perm_list</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>p_name</td>\n",
       "      <td>p_category</td>\n",
       "      <td>info</td>\n",
       "      <td>listed_price</td>\n",
       "      <td></td>\n",
       "      <td>{}</td>\n",
       "      <td>la</td>\n",
       "      <td>perm_list</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>p_name</td>\n",
       "      <td>p_category</td>\n",
       "      <td>info</td>\n",
       "      <td>listed_price</td>\n",
       "      <td></td>\n",
       "      <td>{}</td>\n",
       "      <td>la</td>\n",
       "      <td>perm_list</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>p_name</td>\n",
       "      <td>p_category</td>\n",
       "      <td>info</td>\n",
       "      <td>listed_price</td>\n",
       "      <td></td>\n",
       "      <td>{}</td>\n",
       "      <td>la</td>\n",
       "      <td>perm_list</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>p_name</td>\n",
       "      <td>p_category</td>\n",
       "      <td>info</td>\n",
       "      <td>listed_price</td>\n",
       "      <td></td>\n",
       "      <td>{}</td>\n",
       "      <td>la</td>\n",
       "      <td>perm_list</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Product Name    Category Product Info         Price Overall Features  \\\n",
       "0        p_name  p_category         info  listed_price                    \n",
       "1        p_name  p_category         info  listed_price                    \n",
       "2        p_name  p_category         info  listed_price                    \n",
       "3        p_name  p_category         info  listed_price                    \n",
       "4        p_name  p_category         info  listed_price                    \n",
       "5        p_name  p_category         info  listed_price                    \n",
       "6        p_name  p_category         info  listed_price                    \n",
       "7        p_name  p_category         info  listed_price                    \n",
       "8        p_name  p_category         info  listed_price                    \n",
       "9        p_name  p_category         info  listed_price                    \n",
       "10       p_name  p_category         info  listed_price                    \n",
       "\n",
       "   Category Features Overall Ratings     Review  \n",
       "0                 {}              la  perm_list  \n",
       "1                 {}              la  perm_list  \n",
       "2                 {}              la  perm_list  \n",
       "3                 {}              la  perm_list  \n",
       "4                 {}              la  perm_list  \n",
       "5                 {}              la  perm_list  \n",
       "6                 {}              la  perm_list  \n",
       "7                 {}              la  perm_list  \n",
       "8                 {}              la  perm_list  \n",
       "9                 {}              la  perm_list  \n",
       "10                {}              la  perm_list  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jsonlines\n",
    "df = pd.read_json('data_mining.jsonl', lines=True)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
